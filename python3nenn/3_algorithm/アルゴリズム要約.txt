データ分析:データの特徴や傾向(過去を説明)
機械学習:データ学習後の予測(未来を予測)

機械学習の種類
    ・教師あり学習:数値や分類を予測する学習(回帰・分類 画像認識や文字認識、予測)
    ・教師なし学習:データをまとめる学習(クラスタリング:沢山のデータをグループ分け)
    ・強化学習:経験してうまくなる学習(将棋や囲碁など、いろいろ試してよい結果のときに報酬を渡す)


機械学習の用途
    ・回帰:ある値に関係する値がどんな数値になるのか予測、回帰とは理想の線の形に戻ること
    ・分類:あるデータがどの分類に当てはまるかを予測
    ・クラスタリング:沢山のデータをグループ分け

回帰
        ・線形回帰:予測したい状況(説明変数X)を数値で入力すると、予測結果を数値で出力するアルゴリズム(学習方法)
            LinearRegression(): 線形回帰 最小二乗法で線とデータの誤差を最小にする

分類
        ・ロジスティック回帰:YESかNO等の分類を回帰を使って予測する
            LogisticRegression(): 線形回帰の分類ver.

        ・SVM(サポートベクターマシン):なるべく公平な境界線を引いて分類する
            svm.SVC(kernel="rbf・liner", gamma="1・scale・auto"):
            サポートベクトル(境界線に近い点)からのマージン(余白)の中点距離 ソフトマージンは現実的に誤差を考慮 カーネルトリックで非線形でも線を引ける

        ・決定木:2択の質問で分岐を繰り返して分類する
            DecisionTreeClassifier(max_depth=None, random_state=0): plot_treeでツリー構造を描画 左からYes,Noの順

        ・ランダムフォレスト:決定木をたくさん作って多数決により高精度の予測をする
            RandomForestClassifier()

        ・k-NN(k近傍法):近くにあるk個との距離を調べて、多数決で予測する k-NeighborsClassifier 教師あり学習
            KneighborsClassifier()


クラスタリング
        ・k-means(k平均法):近くにあるk個との距離を調べて、グループ分けする 教師なし学習
            KMeans(n_clusters=3)
            1. 指定したグループ数の仮の重心をランダムに決める
            2. 各グループ(cluster)の平均値を求めて、重心を変更する これを繰り返す